{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9cf2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education\n",
      "[] [] [] []\n",
      "Swinburne University of Technology\n",
      "National University of Computer and Emerging Sciences\n",
      "Adamjee Government Science College\n",
      "\n",
      "            Java\n",
      "          \n",
      "\n",
      "          Machine Learning\n",
      "        \n",
      "\n",
      "          Databases\n",
      "        \n",
      "Education\n",
      "[] [] [] []\n",
      "Macquarie University\n",
      "National University of Computer and Emerging Sciences\n",
      "Education\n",
      "[] [] [] []\n",
      "Deakin University\n",
      "National University of Computer and Emerging Sciences\n",
      "\n",
      "            Android Development\n",
      "          \n",
      "\n",
      "            ASP.NET MVC\n",
      "          \n",
      "\n",
      "            Software Testing\n",
      "          \n",
      "Education\n",
      "[] [] [] []\n",
      "Education\n",
      "[] [] [] []\n",
      "Education\n",
      "[] [] [] []\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=94.0.4606.61)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-65afd142c964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[0mLists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m \u001b[0mget_profiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLists\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-65afd142c964>\u001b[0m in \u001b[0;36mget_profiles\u001b[1;34m(Lists, driver)\u001b[0m\n\u001b[0;32m    114\u001b[0m       \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfulllink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m       \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m       \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m       \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\basha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\basha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mc:\\users\\basha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=94.0.4606.61)\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install selenium\n",
    "\n",
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from parsel import Selector\n",
    "\n",
    "#!pip3 install simplelist\n",
    "#from simplelist import listfromtxt\n",
    "#from simplelist import txtfromlist\n",
    "\n",
    "def write(file,data):\n",
    "    f = open(file, \"a\")\n",
    "    for d in data:\n",
    "        f.write(d+\"\\n\")\n",
    "    f.close()\n",
    "def read(file):\n",
    "    f = open(file, \"r\")\n",
    "    data=f.read().split(\"\\n\")\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def browser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "    \n",
    "    driver_path = './chromedriver'\n",
    "    driver = webdriver.Chrome(executable_path=driver_path,options=options)\n",
    "    driver.get(\"https://www.linkedin.com/login/\")\n",
    "    return driver\n",
    "\n",
    "\n",
    "def login():\n",
    "    file = open(\"./config.txt\")\n",
    "    line = file.readlines()\n",
    "    username = line[0]\n",
    "    password = line[1]\n",
    "    elementID = driver.find_element_by_id('username')\n",
    "    elementID.send_keys(username)\n",
    "    elementID = driver.find_element_by_id('password')\n",
    "    elementID.send_keys(password)\n",
    "    elementID.submit()\n",
    "    return True\n",
    "\n",
    "def profile_urls(ids_file=\"ids1.txt\"):\n",
    "    driver.get('https://www.linkedin.com/school/fastnu/people/?educationEndYear=2019&facetGeoRegion=au%3A0')\n",
    "    rep = 2 #determine the rep enough to scroll all the page\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for i in range(rep):\n",
    "      driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "      time.sleep(5)\n",
    "      new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "      if new_height == last_height:\n",
    "        break\n",
    "      new_height = last_height\n",
    "\n",
    "    src = driver.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    pav = soup.find('div', {'class' : 'artdeco-card pv5 pl5 pr1 mt4'})\n",
    "    all_links = pav.find_all('a', {'class' : 'ember-view link-without-visited-state'})    \n",
    "    profilesID = []\n",
    "    for link in all_links:\n",
    "      profilesID.append(link.get('href'))\n",
    "    \n",
    "    print(len(profilesID))\n",
    "    write(ids_file,profilesID)\n",
    "    \n",
    "    return profilesID\n",
    "\n",
    "def get_profiles(Lists,driver):\n",
    "\n",
    "    names=[]\n",
    "    Current_Company =[]\n",
    "    Current_Job=[]\n",
    "    Total_year=[]\n",
    "    Total_Experience=[]\n",
    "    job_location=[]\n",
    "    \n",
    "    \n",
    "    Last_University=[]\n",
    "    Last_degree=[]\n",
    "    Graduation_start_year=[]\n",
    "    Graduation_end_year=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    skills_set=[]\n",
    "    ProfileIDS=[]\n",
    "    skl1=[]\n",
    "    skl2=[]\n",
    "    skl3=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    import random\n",
    "      \n",
    "    \n",
    "    batch_size=10\n",
    "    counter=0\n",
    "    \n",
    "    for profileID in Lists:\n",
    "      counter+=1\n",
    "      if(counter==batch_size):\n",
    "          counter=0\n",
    "          driver.quit()\n",
    "          driver=browser()\n",
    "          login()\n",
    "      fulllink = 'https://www.linkedin.com' + profileID\n",
    "      driver.get(fulllink)\n",
    "      time.sleep(random.randint(5, 8))\n",
    "      src = driver.page_source\n",
    "      soup = BeautifulSoup(src, 'lxml')\n",
    "      \n",
    "      total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    \n",
    "      for i in range(1, total_height, 5):\n",
    "            driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    \n",
    "        # assigning the source code for the webpage to variable sel\n",
    "      sel = Selector(text=driver.page_source)\n",
    "      \n",
    "      #\"\"\"\n",
    "      \n",
    "      def get_education(sel,soup):\n",
    "          print(\"Education\")\n",
    "          universities=[]\n",
    "          degrees=[]\n",
    "          st_years=[]\n",
    "          end_years=[]\n",
    "          educations=sel.xpath('//*[@id=\"education-section\"]/ul/li/text()').extract()\n",
    "          for education in educations:\n",
    "              print(education)\n",
    "              universities.append(education.xpath('//*[@class=\"pv-entity__degree-info\"]/h3/text()').extract())\n",
    "              print(education.xpath('//*[@class=\"pv-entity__degree-info\"]/h3/text()').extract())\n",
    "              degrees.append(education.xpath('//*[@class=\"pv-entity__degree-name\"]/span[@class=\"pv-entity__comma-item\"]/text()').extract())\n",
    "              st_years.append(education.xpath('//*[@class=\"pv-entity__dates\"]/span[2]/time[1]/text()').extract())\n",
    "              end_years.append(education.xpath('//*[@class=\"pv-entity__dates\"]/span[2]/time[2]/text()').extract())\n",
    "          \n",
    "          print(universities,degrees,st_years,end_years)\n",
    "          return universities,degrees,st_years,end_years\n",
    "      universities,degrees,st_years,end_years=get_education(sel,soup)\n",
    "      #\"\"\"    \n",
    "      \n",
    "    \n",
    "      name = sel.xpath('//*[starts-with(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]/text()').extract_first()\n",
    "      if name:\n",
    "          name = name.strip()\n",
    "\n",
    "      names.append(name)\n",
    "          #print(name)\n",
    "        \n",
    "      #scraping companies\n",
    "      company = sel.xpath('//*[starts-with(@class, \"pv-entity__secondary-title t-14 t-black t-normal\")]/text()').extract_first()\n",
    "      if company:\n",
    "        company = company.strip()\n",
    "      Current_Company.append(company)\n",
    "    \n",
    "    \n",
    "      job_title = sel.xpath('//*[starts-with(@class, \"t-16 t-black t-bold\")]/text()').extract_first()\n",
    "      if job_title:\n",
    "          job_title = job_title.strip()\n",
    "      Current_Job.append(job_title)\n",
    "          #print(jobtitle)\n",
    "        \n",
    "      # job location\n",
    "      job_locations = sel.xpath('//*[starts-with(@class, \"pv-entity__location t-14 t-black--light t-normal block\")]/span[2]/text()').extract_first()\n",
    "      #job_locations = job.find(\"span\", class_=\"job-result-card__location\").text\n",
    "      if job_locations:\n",
    "          job_locations = job_locations.strip()\n",
    "      job_location.append(job_locations)\n",
    "      # print(Job location)\n",
    "      #else: \n",
    "         #job_locations = sel.xpath('//*[starts-with(@class, \"text-body-small inline t-black--light break-words\")]/text()').extract_first()\n",
    "             #if job_locations:\n",
    "                 #location = job_locations.strip()\n",
    "             #job_location.append(job_locations)\n",
    "          # print(location)\n",
    "          \n",
    "      #//*[@id=\"education-section\"]/ul/li/div/div/a/div[2]/div/h3\n",
    "      \n",
    "      #education=sel.xpath('//*[@id=\"education-section\"]')\n",
    "      educations=sel.xpath('//*[@id=\"education-section\"]/ul/li/div/div/a/div[2]/div/h3/text()')\n",
    "      for u in educations:\n",
    "        print(u.extract())\n",
    "          \n",
    "            \n",
    "            \n",
    "      University = sel.xpath('//*[starts-with(@class, \"pv-entity__school-name t-16 t-black t-bold\")]/text()').extract_first()\n",
    "      if University:\n",
    "          University = University.strip()\n",
    "      Last_University.append(University)\n",
    "          # print(location)\n",
    "        \n",
    "        \n",
    "              \n",
    "      degree = sel.xpath('//*[starts-with(@class, \"pv-entity__comma-item\")]/text()').extract_first()\n",
    "      if degree:\n",
    "          degree = degree.strip()\n",
    "      Last_degree.append(degree)\n",
    "          # print(last Degree)\n",
    "        \n",
    "      Grad_start_year = sel.xpath('//*[starts-with(@class, \"pv-entity__dates t-14 t-black--light t-normal\")]/span[2]/time[1]/text()').extract_first()\n",
    "      if Grad_start_year:\n",
    "         Grad_start_year = Grad_start_year.strip()\n",
    "      Graduation_start_year.append(Grad_start_year)\n",
    "          # print(Grad_end_year)\n",
    "        \n",
    "        \n",
    "      Grad_end_year = sel.xpath('//*[starts-with(@class, \"pv-entity__dates t-14 t-black--light t-normal\")]/span[2]/time[2]/text()').extract_first()\n",
    "      if Grad_end_year:\n",
    "         Grad_end_year = Grad_end_year.strip()\n",
    "      Graduation_end_year.append(Grad_end_year)\n",
    "          # print(Grad_end_year)\n",
    "        \n",
    "      \n",
    "    \n",
    "      skill_ary=[]\n",
    "       # skills = sel.xpath('//*[@id=\"ember534\"]/span').extract_first();\n",
    "      for skill in sel.xpath('//*[starts-with(@class, \"pv-skill-category-entity__name-text t-16 t-black t-bold\")]'):\n",
    "            #print(li.xpath('.//@href').get())\n",
    "            print(skill.xpath('.//text()').get());\n",
    "            skill_ary.append(skill.xpath('.//text()').get())\n",
    "      if len(skill_ary) > 0:\n",
    "        skl1.append(skill_ary[0].strip())\n",
    "      if len(skill_ary) > 1:\n",
    "        skl2.append(skill_ary[1].strip())\n",
    "      if len(skill_ary) > 2:\n",
    "        skl3.append(skill_ary[2].strip())\n",
    "      #skills = sel.xpath('//*[starts-with(@class, \"pv-skill-category-entity__name-text t-16 t-black t-bold\")]//text()').extract_first()\n",
    "     \n",
    "     ##Graduation_year = sel.xpath('//*[starts-with(@class, \"pv-entity__secondary-title \"pv-entity__degree-name t-14 t-black t-normal\")]/span()/span()/text()').extract_first()\n",
    "     \n",
    "      time.sleep(random.randint(2, 8))\n",
    "      #time.sleep(5)  \n",
    "      #for skill in skills:\n",
    "       #     skills = sel.xpath('//*[starts-with(@class,\"pv-skill-category-entity__name-text t-16 t-black t-bold\")]/text()').extract()\n",
    "      #skills_set.append(skills)\n",
    "         \n",
    "    \n",
    "      Dates_Employed = sel.xpath('//*[starts-with(@class, \"pv-entity__date-range t-14 t-black--light t-normal\")]/span[2]/text()').extract_first()\n",
    "      if Dates_Employed:\n",
    "         Dates_Employed = Dates_Employed.strip()\n",
    "      Total_year.append(Dates_Employed)\n",
    "          # print(Dates_Employed)\n",
    "        \n",
    "        \n",
    "      Experience = sel.xpath('//*[starts-with(@class, \"pv-entity__bullet-item-v2\")]/text()').extract_first()\n",
    "      if Experience:\n",
    "            Experience = Experience.strip()\n",
    "      Total_Experience.append(Experience)\n",
    "          # print(Experience)\n",
    "         \n",
    "            \n",
    "            \n",
    "      profileID = driver.current_url\n",
    "      ProfileIDS.append(profileID)\n",
    "         \n",
    "    \n",
    "      #Print what information is being write to the CSV file\n",
    "      rows = [name,company,job_title,Total_year,Total_Experience,job_location,degree,Graduation_start_year,Graduation_end_year,skl1,skl2,skl3,University,profileID]\n",
    "      \n",
    "      \n",
    "      if(counter==batch_size):\n",
    "          print('Writing to CSV:', rows)\n",
    "          df = pd.DataFrame(list(zip(names,Current_Company,Current_Job,Total_year,Total_Experience,job_location,Last_degree,Graduation_start_year,Graduation_end_year,skl1,skl2,skl3,Last_University,ProfileIDS)), \n",
    "                   columns =['Name', 'Current_Company', 'Current_Job', 'Total_year',   'Total_Experience',  'job_location',  'Last_degree' ,  'Graduation_start_year', 'Graduation_end_year','skill_1','skill_2','skill_3',  'Last_University', 'ProfileIDS'])\n",
    "        \n",
    "          #print(df)\n",
    "          df.to_csv('./Scrapdata1111.csv', index=False)\n",
    "\n",
    "    df = pd.DataFrame(list(zip(names,Current_Company,Current_Job,Total_year,Total_Experience,job_location,Last_degree,Graduation_start_year,Graduation_end_year,skl1,skl2,skl3,Last_University,ProfileIDS)),\n",
    "                  columns =['Name', 'Current_Company', 'Current_Job', 'Total_year',   'Total_Experience',  'job_location',  'Last_degree' ,  'Graduation_start_year', 'Graduation_end_year','skill_1','skill_2','skill_3',  'Last_University', 'ProfileIDS'])\n",
    "    df.to_csv('./Scrapdata1111.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ids_file=\"ProfilesID13.txt\"\n",
    "driver=browser()\n",
    "login()\n",
    "#profilesID=profile_urls(ids_file)\n",
    "\n",
    "Lists=read(ids_file)\n",
    "get_profiles(Lists,driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6033f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b54bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ab36f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
